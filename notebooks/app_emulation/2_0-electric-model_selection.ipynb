{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal of this notebook is to test wide range of potential models.\n",
    "\n",
    "1. Lazypredict\n",
    "-> choose promising models\n",
    "2. GridSearch on selection of promising models\n",
    "3. Summary of hot candidates including metric, high influencing variables, pca of cluster, etc.\n",
    "\n",
    "\n",
    "Open todo's-> (maybe other notebook)\n",
    "- hyperparameter optimization\n",
    "- dimension reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lazypredict.Supervised import LazyRegressor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from config import MERGED_ELECTRIC_FILE, DENSITY_THRESHOLD, DATABASE_FILE_INDEX, DATABASE_FILE_DTYPES, REPLACE_STRING_OTHER, ELECTRIC_TARGET\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset for electric cars\n",
    "df = pd.read_csv(MERGED_ELECTRIC_FILE, dtype=DATABASE_FILE_DTYPES, index_col=DATABASE_FILE_INDEX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing for electric dataset\n",
    "\n",
    "(later added to 1_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['member_state', 'manufacturer_name_eu', 'vehicle_type',\n",
       "       'commercial_name', 'category_of_vehicle', 'fuel_type', 'fuel_mode',\n",
       "       'innovative_technologies', 'mass_vehicle', 'weltp_test_mass',\n",
       "       'engine_capacity', 'engine_power', 'erwltp', 'year', 'electric_range',\n",
       "       'electric_energy_consumption', 'fuel_consumption',\n",
       "       'specific_co2_emissions'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3945297 entries, 56003781 to 134630842\n",
      "Data columns (total 18 columns):\n",
      " #   Column                       Dtype  \n",
      "---  ------                       -----  \n",
      " 0   member_state                 object \n",
      " 1   manufacturer_name_eu         object \n",
      " 2   vehicle_type                 object \n",
      " 3   commercial_name              object \n",
      " 4   category_of_vehicle          object \n",
      " 5   fuel_type                    object \n",
      " 6   fuel_mode                    object \n",
      " 7   innovative_technologies      object \n",
      " 8   mass_vehicle                 float64\n",
      " 9   weltp_test_mass              float64\n",
      " 10  engine_capacity              float64\n",
      " 11  engine_power                 float64\n",
      " 12  erwltp                       float64\n",
      " 13  year                         int64  \n",
      " 14  electric_range               float64\n",
      " 15  electric_energy_consumption  float64\n",
      " 16  fuel_consumption             float64\n",
      " 17  specific_co2_emissions       float64\n",
      "dtypes: float64(9), int64(1), object(8)\n",
      "memory usage: 571.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_categorical_quantitive_cols(df):\n",
    "    cat_cols = pd.DataFrame.select_dtypes(df, include=[\"object\"]).columns\n",
    "    quant_cols = df.select_dtypes(exclude=[\"object\"]).columns\n",
    "\n",
    "    return cat_cols, quant_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_be_dropped = list()\n",
    "\n",
    "cat_cols, quant_cols = categorize_categorical_quantitive_cols(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove columns below density threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "member_state                  0.00\n",
      "manufacturer_name_eu          0.00\n",
      "vehicle_type                  0.00\n",
      "commercial_name               0.01\n",
      "category_of_vehicle           0.01\n",
      "fuel_type                     0.00\n",
      "fuel_mode                     0.00\n",
      "innovative_technologies       1.00\n",
      "mass_vehicle                  0.00\n",
      "weltp_test_mass               0.04\n",
      "engine_capacity               1.00\n",
      "engine_power                  0.07\n",
      "erwltp                        1.00\n",
      "year                          0.00\n",
      "electric_range                0.12\n",
      "electric_energy_consumption   0.04\n",
      "fuel_consumption              1.00\n",
      "specific_co2_emissions        0.00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "missing_percentage = df.isna().sum() / len(df)\n",
    "print(missing_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to be dropped due to availability density below threshold: ['innovative_technologies', 'engine_capacity', 'erwltp', 'fuel_consumption']\n"
     ]
    }
   ],
   "source": [
    "cols_to_be_dropped = list()\n",
    "\n",
    "for col, percentage in missing_percentage.items():\n",
    "    if percentage > DENSITY_THRESHOLD:\n",
    "        cols_to_be_dropped.append(col)\n",
    "\n",
    "print(f\"Columns to be dropped due to availability density below threshold: {cols_to_be_dropped}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "member_state                  0.00\n",
      "manufacturer_name_eu          0.00\n",
      "vehicle_type                  0.00\n",
      "commercial_name               0.01\n",
      "category_of_vehicle           0.01\n",
      "fuel_type                     0.00\n",
      "fuel_mode                     0.00\n",
      "innovative_technologies       1.00\n",
      "mass_vehicle                  0.00\n",
      "weltp_test_mass               0.04\n",
      "engine_capacity               1.00\n",
      "engine_power                  0.07\n",
      "erwltp                        1.00\n",
      "year                          0.00\n",
      "electric_range                0.12\n",
      "electric_energy_consumption   0.04\n",
      "fuel_consumption              1.00\n",
      "specific_co2_emissions        0.00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "missing_percentage = df.isna().sum() / len(df)\n",
    "print(missing_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantitative columns\n",
    "\n",
    "- replace missing values with median of variable\n",
    "- drop missing values if replacement is no option (e.g. for target variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"specific_co2_emissions\"].value_counts(normalize=True)\n",
    "# -> all values are 0 -> no use for us\n",
    "cols_to_be_dropped.append(\"specific_co2_emissions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# electric_energy_consumption is our target and we should only keep rows with value\n",
    "df.dropna(subset=[\"electric_energy_consumption\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping columns:  ['innovative_technologies', 'engine_capacity', 'erwltp', 'fuel_consumption', 'specific_co2_emissions']\n"
     ]
    }
   ],
   "source": [
    "print(\"Dropping columns: \", cols_to_be_dropped)\n",
    "df.drop(columns=cols_to_be_dropped, inplace=True)\n",
    "\n",
    "# reinit\n",
    "cols_to_be_dropped = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NaN with median\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "cat_cols, quant_cols = categorize_categorical_quantitive_cols(df)\n",
    "# make sure we don't accidentely manipulate target variable\n",
    "quant_cols_replace = list(quant_cols)\n",
    "quant_cols_replace.remove(ELECTRIC_TARGET)\n",
    "# we don't want to replace anything in year column\n",
    "quant_cols_replace.remove(\"year\")\n",
    "\n",
    "df[quant_cols] = imputer.fit_transform(df[quant_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "member_state                  0.00\n",
      "manufacturer_name_eu          0.00\n",
      "vehicle_type                  0.00\n",
      "commercial_name               0.01\n",
      "category_of_vehicle           0.00\n",
      "fuel_type                     0.00\n",
      "fuel_mode                     0.00\n",
      "mass_vehicle                  0.00\n",
      "weltp_test_mass               0.00\n",
      "engine_power                  0.00\n",
      "year                          0.00\n",
      "electric_range                0.00\n",
      "electric_energy_consumption   0.00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "missing_percentage = df.isna().sum() / len(df)\n",
    "print(missing_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze and preprocess columns based on value distribution & uniqueness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "member_state  unique vals:  29\n",
      "manufacturer_name_eu  unique vals:  72\n",
      "vehicle_type  unique vals:  286\n",
      "commercial_name  unique vals:  1452\n",
      "category_of_vehicle  unique vals:  4\n",
      "fuel_type  unique vals:  1\n",
      "fuel_mode  unique vals:  1\n"
     ]
    }
   ],
   "source": [
    "# analyze uniqueness\n",
    "for col in cat_cols:\n",
    "    len_unique = len(df[col].unique())\n",
    "    print(col, \" unique vals: \", len_unique)\n",
    "    if len_unique == 1:\n",
    "        # we don't need cols with only one value -> drop\n",
    "        cols_to_be_dropped.append(col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping columns:  ['fuel_type', 'fuel_mode']\n"
     ]
    }
   ],
   "source": [
    "print(\"Dropping columns: \", cols_to_be_dropped)\n",
    "df.drop(columns=cols_to_be_dropped, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Reduce number of unique values through adding a \"other\" value/class representing all values below a certain threshold.\n",
    "- Additionally we'll replace Na values with REPLACE_STRING_OTHER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace Na values for cat_cols with REPLACE_STRING_OTHER\n",
    "\n",
    "cat_cols, quant_cols = categorize_categorical_quantitive_cols(df)\n",
    "df[cat_cols] = df[cat_cols].fillna(value=REPLACE_STRING_OTHER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_unique_col_vals_through_other(df, col, threshold=0.01):\n",
    "    # check if we can reduce the number of unique values in a column\n",
    "    # by grouping the values that have a frequency of less than threshold\n",
    "    # into a new category\n",
    "    # returns the modified dataframe and the new unique values\n",
    "    value_counts = df[col].value_counts(normalize=True)\n",
    "    other_vals = value_counts[value_counts < threshold].index\n",
    "    df[col] = df[col].apply(lambda x: REPLACE_STRING_OTHER if x in other_vals else x)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "member_state           0.00\n",
      "manufacturer_name_eu   0.00\n",
      "vehicle_type           0.00\n",
      "commercial_name        0.00\n",
      "category_of_vehicle    0.00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "cat_cols, quant_cols = categorize_categorical_quantitive_cols(df)\n",
    "\n",
    "missing_percentage = df[cat_cols].isna().sum() / len(df)\n",
    "print(missing_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced unique vals of manufacturer_name_eu to:  22\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "manufacturer_name_eu\n",
       "TESLA                      0.14\n",
       "VOLKSWAGEN                 0.12\n",
       "BMW AG                     0.08\n",
       "STELLANTIS AUTO            0.07\n",
       "RENAULT                    0.07\n",
       "MERCEDES-BENZ AG           0.06\n",
       "AUDI AG                    0.05\n",
       "other                      0.05\n",
       "KIA                        0.04\n",
       "SKODA                      0.04\n",
       "DACIA                      0.04\n",
       "STELLANTIS EUROPE          0.04\n",
       "SAIC MOTOR CORPORATION     0.03\n",
       "VOLVO                      0.03\n",
       "PSA                        0.03\n",
       "HYUNDAI                    0.03\n",
       "HYUNDAI CZECH              0.02\n",
       "SEAT                       0.02\n",
       "NISSAN AUTOMOTIVE EUROPE   0.02\n",
       "FORD WERKE GMBH            0.01\n",
       "POLESTAR                   0.01\n",
       "FIAT GROUP                 0.01\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess manufacturer_name_eu to reduce number of unique values for future encoding\n",
    "reduce_unique_col_vals_through_other(df, \"manufacturer_name_eu\", threshold=0.01)\n",
    "print(\"Reduced unique vals of manufacturer_name_eu to: \", len(df[\"manufacturer_name_eu\"].unique()))\n",
    "df[\"manufacturer_name_eu\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced unique vals of vehicle_type to:  58\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "vehicle_type\n",
       "003       0.10\n",
       "U         0.09\n",
       "E2        0.06\n",
       "FA1       0.04\n",
       "E1        0.04\n",
       "NY        0.04\n",
       "3         0.04\n",
       "DBG       0.04\n",
       "other     0.03\n",
       "X         0.03\n",
       "AG        0.03\n",
       "FZ        0.03\n",
       "F2B       0.02\n",
       "OSE       0.02\n",
       "FML2E     0.02\n",
       "AA        0.02\n",
       "NE        0.02\n",
       "V         0.02\n",
       "451       0.02\n",
       "RCB       0.02\n",
       "GE        0.02\n",
       "K1        0.02\n",
       "CV        0.02\n",
       "ZE1       0.02\n",
       "G4C       0.01\n",
       "SEH3      0.01\n",
       "AH        0.01\n",
       "LSK       0.01\n",
       "DE        0.01\n",
       "G3XE      0.01\n",
       "B         0.01\n",
       "SG2       0.01\n",
       "ZS1       0.01\n",
       "U1X       0.01\n",
       "BMWi-1    0.01\n",
       "Y1A       0.01\n",
       "204 X     0.01\n",
       "BMWi-N    0.01\n",
       "DR        0.01\n",
       "E2EQEW    0.01\n",
       "EAM1(M)   0.00\n",
       "E         0.00\n",
       "005       0.00\n",
       "AH2       0.00\n",
       "EP21      0.00\n",
       "EB        0.00\n",
       "EP22-L    0.00\n",
       "AG0       0.00\n",
       "SC2E      0.00\n",
       "FH1       0.00\n",
       "BMWI-N    0.00\n",
       "SK3       0.00\n",
       "639/2     0.00\n",
       "FW        0.00\n",
       "CE        0.00\n",
       "FE0E      0.00\n",
       "OS        0.00\n",
       "HX11      0.00\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess vehicle_type to reduce number of unique values for future encoding\n",
    "reduce_unique_col_vals_through_other(df, \"vehicle_type\", threshold=0.0025)\n",
    "print(\"Reduced unique vals of vehicle_type to: \", len(df[\"vehicle_type\"].unique()))\n",
    "df[\"vehicle_type\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced unique vals of commercial_name to:  181\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "commercial_name\n",
       "MODEL Y        0.07\n",
       "MODEL 3        0.06\n",
       "other          0.05\n",
       "500            0.04\n",
       "SPRING         0.04\n",
       "               ... \n",
       "E-TRON S       0.00\n",
       "Q4 E-TRON      0.00\n",
       "iX1 xDrive30   0.00\n",
       "600            0.00\n",
       "e-tron 55      0.00\n",
       "Name: proportion, Length: 181, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess commercial_name to reduce number of unique values for future encoding\n",
    "reduce_unique_col_vals_through_other(df, \"commercial_name\", threshold=0.0005)\n",
    "print(\"Reduced unique vals of commercial_name to: \", len(df[\"commercial_name\"].unique()))\n",
    "df[\"commercial_name\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding\n",
    "cat_cols, quant_cols = categorize_categorical_quantitive_cols(df)\n",
    "\n",
    "ct_electric = ColumnTransformer(transformers=[(\"encoder\", OneHotEncoder(sparse_output=False), cat_cols)], remainder=\"passthrough\")\n",
    "transformed_array = ct_electric.fit_transform(df)\n",
    "encoder_feature_names = ct_electric.named_transformers_[\"encoder\"].get_feature_names_out(cat_cols)\n",
    "\n",
    "preserved_col_names = list(encoder_feature_names)\n",
    "preserved_col_names.extend(list(quant_cols))\n",
    "\n",
    "df_enc = pd.DataFrame(transformed_array, columns=preserved_col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset\n",
    "- features, target\n",
    "- train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = ELECTRIC_TARGET)\n",
    "y= df[ELECTRIC_TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols, quant_cols = categorize_categorical_quantitive_cols(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols, quant_cols = categorize_categorical_quantitive_cols(X)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train[quant_cols] = sc.fit_transform(X_train[quant_cols])\n",
    "X_test[quant_cols] = sc.fit_transform(X_test[quant_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lazy Predict\n",
    "\n",
    "We'll use LazyRegressor as we're dealing with a supervised learning regression problem and want to check potential models for our usecase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 8/42 [06:03<12:15, 21.64s/it]   "
     ]
    }
   ],
   "source": [
    "reg = LazyRegressor(verbose=0,ignore_warnings=False, custom_metric=None )\n",
    "models,predictions = reg.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
